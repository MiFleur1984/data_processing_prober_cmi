{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choix du fichier à traiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Ouvrir une boîte de dialogue pour sélectionner un fichier CSV\n",
    "fichier_csv = filedialog.askopenfile(filetypes=[(\"Fichiers CSV\", \"*.csv\")])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stockage du cvs ligne par ligne dans une liste \"row\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "with open(fichier_csv.name, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\",\")\n",
    "    for row in reader:\n",
    "        rows.append(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la liste filtrée en DataFrame pandas\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x) #enlève l'espace\n",
    "# #print(df.head())\n",
    "# print(\"avant: \",df.columns)\n",
    "\n",
    "# # charger le fichier CSV avec un nom de colonne\n",
    "# df.columns = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "# # afficher les noms de colonnes\n",
    "# print(\"après: \", df.columns)\n",
    "\n",
    "# Remplacer les valeurs NaN par une valeur de remplacement\n",
    "df.fillna(value='NA', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "création de dictionnaires pour chaque block de mesure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\michel.jeanneret\\Documents\\PROFESSIONNEL\\python\\Prober_station\\data_processing_prober_cmi.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Si la cellule de la colonne A contient \"DataValue\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39melif\u001b[39;00m row[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDataValue\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m# Ajouter les valeurs dans le DataFrame en cours\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     dfs[current_df] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat([dfs[current_df], pd\u001b[39m.\u001b[39;49mDataFrame([row])])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m# Resetter l'index\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     dfs[current_df] \u001b[39m=\u001b[39m dfs[current_df]\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\SKe_env\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\SKe_env\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:360\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[39malong the other axes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[39mValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    347\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    348\u001b[0m     objs,\n\u001b[0;32m    349\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[0;32m    358\u001b[0m )\n\u001b[1;32m--> 360\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\SKe_env\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:591\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    589\u001b[0m         obj_labels \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39maxes[\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m ax]\n\u001b[0;32m    590\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m new_labels\u001b[39m.\u001b[39mequals(obj_labels):\n\u001b[1;32m--> 591\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39;49mget_indexer(new_labels)\n\u001b[0;32m    593\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[0;32m    595\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[0;32m    596\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_axes, concat_axis\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbm_axis, copy\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[0;32m    597\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\SKe_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3721\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3718\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3720\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 3721\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidIndexError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requires_unique_msg)\n\u001b[0;32m   3723\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   3724\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "# récupérer le nombre de colonnes dans df\n",
    "num_cols = df.shape[1]\n",
    "\n",
    "# Initialiser les variables\n",
    "dfs = {}\n",
    "current_df = None\n",
    "\n",
    "\n",
    "# Parcourir chaque ligne du tableau\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    \n",
    "    # Si la cellule de la colonne B contient \"TestRecord.Remarks\"\n",
    "    if row[1] == 'TestRecord.Remarks':\n",
    "        # Enregistrer le nom du DataFrame en cours\n",
    "        current_df = row[2]\n",
    "        # créer un nouveau DataFrame avec les mêmes colonnes, mais sans données\n",
    "        dfs[current_df] = pd.DataFrame(columns=range(num_cols))\n",
    "\n",
    "    #elif pour choper nom des colonnes à faire ici\n",
    "    elif row[0] == 'DataName':\n",
    "        # Ajouter le nom des colonnes dans le DataFrame en cours\n",
    "        dfs[current_df] = pd.concat([dfs[current_df], pd.DataFrame([row])])\n",
    "\n",
    "\n",
    "    # Si la cellule de la colonne A contient \"DataValue\"\n",
    "    elif row[0] == 'DataValue':\n",
    "        # Ajouter les valeurs dans le DataFrame en cours\n",
    "        dfs[current_df] = pd.concat([dfs[current_df], pd.DataFrame([row])])\n",
    "        # Resetter l'index\n",
    "        dfs[current_df] = dfs[current_df].reset_index(drop=True)\n",
    "        # utiliser la première ligne pour nommer les colonnes\n",
    "        dfs[current_df].columns = dfs[current_df].iloc[0]\n",
    "        # supprimer la première ligne du DataFrame\n",
    "        dfs[current_df] = dfs[current_df].drop(0)\n",
    "\n",
    "        \n",
    "\n",
    "#print(df)\n",
    "\n",
    "dict_keys = list(dfs.keys())\n",
    "\n",
    "#print(dfs[1])\n",
    "\n",
    "# # Afficher les DataFrames\n",
    "print(dict_keys[1])\n",
    "print(dfs[dict_keys[1]])\n",
    "\n",
    "# print(dfs['nom2'])\n",
    "# print(dfs['nom3'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "version GPT code du 20.04.2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blank DSP BS 20V', 'blank DSP BS 10V', 'blank DSP FS 10V spot2', 'blank DSP FS 20V spot2', 'blank DSP FS 20V', 'blank DSP FS 10V']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Créer le tableau\n",
    "# df = pd.DataFrame({'A': ['cx', 'qq', 'qq', 'pp', 'qq', 'DataValue', 'DataValue', 'qq', 'wd', 'qq', 'qq', 'pp', 'qq', 'DataValue', 'DataValue', 'ds', 'sg', 'sd', 'qq', 'qq', 'gds', 'qq', 'DataValue', 'DataValue'],\n",
    "#                    'B': ['csd', 'TestRecord.Remarks', 'qq', 'p', 'ff', 'val1', 'val3', 'ee', 'ww', 'TestRecord.Remarks', 'qq', 'p', 'fr', 'val5', 'val7', 'vfre', 'ssfd', 'ffw', 'TestRecord.Remarks', 'qq', 'df', 'fr', 'val9', 'val11'],\n",
    "#                    'C': ['dd', 'nom1', 'qq', 'dd', 'a', 'val2', 'val4', 'ff', 'ss', 'nom2', 'qq', 'dd', 'a', 'val6', 'val8', 'sd', 'fs', 'sfdf', 'nom3', 'qq', 'ew', 'a', 'val10', 'val12']})\n",
    "\n",
    "# Initialiser les variables\n",
    "list_dict = []\n",
    "dicts = {}\n",
    "current_dict = None\n",
    "\n",
    "# Parcourir chaque ligne du tableau\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    \n",
    "    # Si la cellule de la colonne B contient \"TestRecord.Remarks\"\n",
    "    if row['B'] == 'TestRecord.Remarks':\n",
    "        # Enregistrer le nom du dictionnaire en cours\n",
    "        current_dict = row['C']\n",
    "        list_dict.append(current_dict)\n",
    "        # Initialiser le dictionnaire avec le nom de la cellule à droite\n",
    "        dicts[current_dict] = {}\n",
    "    # Si la cellule de la colonne A contient \"DataValue\"\n",
    "    elif row['A'] == 'DataValue':\n",
    "        # Ajouter les valeurs dans le dictionnaire en cours\n",
    "        dicts[current_dict][row['B']] = row['C']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blank DSP BS 20V', 'blank DSP BS 10V', 'blank DSP FS 10V spot2', 'blank DSP FS 20V spot2', 'blank DSP FS 20V', 'blank DSP FS 10V']\n",
      "{'-10': '42', '-9': '41', '-8': '40', '-7': '39', '-6': '38', '-5': '37', '-4': '36', '-3': '35', '-2': '34', '-1': '33', '0': '32', '1': '31', '2': '30', '3': '29', '4': '28', '5': '27', '6': '26', '7': '25', '8': '24', '9': '23', '10': '22'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Afficher les dictionnaires\n",
    "print(list_dict)\n",
    "\n",
    "print(dicts[list_dict[1]])\n",
    "# print(dicts['nom2'])\n",
    "# print(dicts['nom3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "             0                   1                       2   3   4\n",
      "110   MetaData  TestRecord.Remarks        blank DSP BS 20V  NA  NA\n",
      "373   MetaData  TestRecord.Remarks        blank DSP BS 10V  NA  NA\n",
      "636   MetaData  TestRecord.Remarks  blank DSP FS 10V spot2  NA  NA\n",
      "899   MetaData  TestRecord.Remarks  blank DSP FS 20V spot2  NA  NA\n",
      "1162  MetaData  TestRecord.Remarks        blank DSP FS 20V  NA  NA\n",
      "1425  MetaData  TestRecord.Remarks        blank DSP FS 10V  NA  NA\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Remplacer les valeurs NaN par une valeur de remplacement\n",
    "df.fillna(value='NA', inplace=True)\n",
    "print(type(df[0][0]))\n",
    "\n",
    "# Recherche de la chaîne de caractères \"example\" dans la colonne \"nom_colonne\"\n",
    "liste_nom_mesures = df[df[1].str.contains(\"TestRecord.Remarks\")]\n",
    "print(liste_nom_mesures)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110           blank DSP BS 20V\n",
      "373           blank DSP BS 10V\n",
      "636     blank DSP FS 10V spot2\n",
      "899     blank DSP FS 20V spot2\n",
      "1162          blank DSP FS 20V\n",
      "1425          blank DSP FS 10V\n",
      "Name: 2, dtype: object\n",
      "110\n",
      "110\n",
      "373\n",
      "373\n",
      "636\n",
      "636\n",
      "899\n",
      "899\n",
      "1162\n",
      "1162\n",
      "1425\n",
      "1425\n",
      "{'blank DSP BS 20V': [], 'blank DSP BS 10V': [], 'blank DSP FS 10V spot2': [], 'blank DSP FS 20V spot2': [], 'blank DSP FS 20V': [], 'blank DSP FS 10V': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michel.jeanneret\\AppData\\Local\\Temp\\ipykernel_19880\\703349057.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  sub_df = df.loc[idx[0]:idx[-1]][df[0].str.contains(\"DataValue\")]\n"
     ]
    }
   ],
   "source": [
    "dicts = {}\n",
    "print(liste_nom_mesures[2])\n",
    "for name in liste_nom_mesures[2].unique():\n",
    "    idx = liste_nom_mesures[liste_nom_mesures[2] == name].index\n",
    "    print(idx[0])\n",
    "    print(idx[-1])\n",
    "\n",
    "def create_dicts(df,index_i,index_ii)\n",
    "    sub_df = df.loc[index_i:index_ii][df[0].str.contains(\"DataValue\")]\n",
    "    sub_dict = {name: sub_df[1].values.tolist()}\n",
    "    dicts.update(sub_dict)\n",
    "\n",
    "for x in range(len()):\n",
    "    deposition = specific_line_list(file_name, prime_id_lines[x], purge_lines[x]+18) #selecting only the desired lines with specific_line_list function    \n",
    "    wafer_log.append(deposition)\n",
    "\n",
    "print(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([110], dtype='int64')\n",
      "Int64Index([373], dtype='int64')\n",
      "Int64Index([636], dtype='int64')\n",
      "Int64Index([899], dtype='int64')\n",
      "Int64Index([1162], dtype='int64')\n",
      "Int64Index([1425], dtype='int64')\n",
      "idx :  [Int64Index([110], dtype='int64'), Int64Index([373], dtype='int64'), Int64Index([636], dtype='int64'), Int64Index([899], dtype='int64'), Int64Index([1162], dtype='int64'), Int64Index([1425], dtype='int64')]\n"
     ]
    }
   ],
   "source": [
    "tab_idx = []\n",
    "\n",
    "for name in liste_nom_mesures[2].unique():\n",
    "    idx = liste_nom_mesures[liste_nom_mesures[2] == name].index\n",
    "    print(idx)\n",
    "    tab_idx.append(idx)\n",
    "    \n",
    "print(\"idx : \",tab_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Int64Index([110], dtype='int64')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\michel.jeanneret\\Documents\\PROFESSIONNEL\\python\\Prober_station\\data_processing_prober_cmi.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dicts \u001b[39m=\u001b[39m {}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m tab_idx:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     sub_df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mloc[index:index][df[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcontains(\u001b[39m\"\u001b[39m\u001b[39mDataValue\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     sub_dict \u001b[39m=\u001b[39m {name: sub_df[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     dicts\u001b[39m.\u001b[39mupdate(sub_dict)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\prober_station\\lib\\site-packages\\pandas\\core\\indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    964\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m    966\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m--> 967\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\prober_station\\lib\\site-packages\\pandas\\core\\indexing.py:1180\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[0;32m   1179\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1180\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_slice_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1181\u001b[0m \u001b[39melif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m   1182\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getbool_axis(key, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\prober_station\\lib\\site-packages\\pandas\\core\\indexing.py:1214\u001b[0m, in \u001b[0;36m_LocIndexer._get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1211\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1213\u001b[0m labels \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m-> 1214\u001b[0m indexer \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39;49mslice_indexer(slice_obj\u001b[39m.\u001b[39;49mstart, slice_obj\u001b[39m.\u001b[39;49mstop, slice_obj\u001b[39m.\u001b[39;49mstep)\n\u001b[0;32m   1216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(indexer, \u001b[39mslice\u001b[39m):\n\u001b[0;32m   1217\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_slice(indexer, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\prober_station\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6274\u001b[0m, in \u001b[0;36mIndex.slice_indexer\u001b[1;34m(self, start, end, step, kind)\u001b[0m\n\u001b[0;32m   6231\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6232\u001b[0m \u001b[39mCompute the slice indexer for input labels and step.\u001b[39;00m\n\u001b[0;32m   6233\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6270\u001b[0m \u001b[39mslice(1, 3, None)\u001b[39;00m\n\u001b[0;32m   6271\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6272\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deprecated_arg(kind, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mslice_indexer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 6274\u001b[0m start_slice, end_slice \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mslice_locs(start, end, step\u001b[39m=\u001b[39;49mstep)\n\u001b[0;32m   6276\u001b[0m \u001b[39m# return a slice\u001b[39;00m\n\u001b[0;32m   6277\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(start_slice):\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\prober_station\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6484\u001b[0m, in \u001b[0;36mIndex.slice_locs\u001b[1;34m(self, start, end, step, kind)\u001b[0m\n\u001b[0;32m   6482\u001b[0m start_slice \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   6483\u001b[0m \u001b[39mif\u001b[39;00m start \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 6484\u001b[0m     start_slice \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_slice_bound(start, \u001b[39m\"\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   6485\u001b[0m \u001b[39mif\u001b[39;00m start_slice \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   6486\u001b[0m     start_slice \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\prober_station\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6397\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[1;34m(self, label, side, kind)\u001b[0m\n\u001b[0;32m   6395\u001b[0m \u001b[39m# we need to look up the label\u001b[39;00m\n\u001b[0;32m   6396\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 6397\u001b[0m     slc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   6398\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   6399\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\prober_station\\lib\\site-packages\\pandas\\core\\indexes\\range.py:388\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    387\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[0;32m    389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m    390\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mget_loc(key, method\u001b[39m=\u001b[39mmethod, tolerance\u001b[39m=\u001b[39mtolerance)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\prober_station\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5637\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5633\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   5634\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5635\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5636\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5637\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Int64Index([110], dtype='int64')"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "dicts = {}\n",
    "for index in tab_idx:\n",
    "    sub_df = df.loc[index:index][df[0].str.contains(\"DataValue\")]\n",
    "    sub_dict = {name: sub_df[1].values.tolist()}\n",
    "    dicts.update(sub_dict)\n",
    "\n",
    "print(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blank DSP BS 10V\n",
      "{'blank DSP BS 20V': {}, 'blank DSP BS 10V': {}, 'blank DSP FS 10V spot2': {}, 'blank DSP FS 20V spot2': {}, 'blank DSP FS 20V': {}, 'blank DSP FS 10V': {}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(liste_nom_mesures.iloc[1, 2])\n",
    "\n",
    "# Extraire les noms uniques de la troisième colonne\n",
    "noms_dictionnaires = liste_nom_mesures.iloc[:,2].unique()\n",
    "\n",
    "# Créer un dictionnaire vide pour chaque nom de la troisième colonne\n",
    "dict_nom_mesure = {}\n",
    "for nom in noms_dictionnaires:\n",
    "    dict_nom_mesure[nom] = {}\n",
    "\n",
    "# Afficher les dict_nom_mesure créés\n",
    "print(dict_nom_mesure)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la prochaine section, il faut remplacer 200 et 400 par les valeurs d'index des noms des mesures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0    1   2                        3                   4\n",
      "485  DataValue  -10   1              -0.00422186   1675.827858962328\n",
      "486  DataValue   -9   2   -0.0036251400000000002  1732.0816156857311\n",
      "487  DataValue   -8   3              -0.00306718  1858.2007042580669\n",
      "488  DataValue   -7   4              -0.00254883  2006.5413247185829\n",
      "489  DataValue   -6   5              -0.00207044  2157.1482500134821\n",
      "490  DataValue   -5   6   -0.0016216800000000001  2316.9601482854491\n",
      "491  DataValue   -4   7              -0.00120724  2533.5601714206809\n",
      "492  DataValue   -3   8  -0.00083227700000000008  2827.9023468761575\n",
      "493  DataValue   -2   9             -0.000500002  3198.5977347530838\n",
      "494  DataValue   -1  10             -0.000207003  4007.9685227779305\n",
      "495  DataValue    0  11  -9.9608499999999988E-07   9558.487717247699\n",
      "496  DataValue    1  12              2.23512E-06  548450.83206846856\n",
      "497  DataValue    2  13   2.6505500000000004E-06  2406536.1521893465\n",
      "498  DataValue    3  14              3.06619E-06  3030762.2367025316\n",
      "499  DataValue    4  15   3.3104500000000002E-06    3388452.15505557\n",
      "500  DataValue    5  16   3.6564300000000002E-06  2894314.1199114337\n",
      "501  DataValue    6  17              4.00146E-06  3056701.8187375809\n",
      "502  DataValue    7  18   4.3107300000000005E-06  2522863.4500157675\n",
      "503  DataValue    8  19   4.7942100000000005E-06   2413709.872073377\n",
      "504  DataValue    9  20   5.1393300000000005E-06  2968460.1113172537\n",
      "505  DataValue   10  21   5.4679600000000006E-06  4589893.0554918144\n",
      "506  DataValue   10  22               5.3572E-06  1965099.8270712162\n",
      "507  DataValue    9  23   4.9590800000000008E-06  3058571.6470408328\n",
      "508  DataValue    8  24               4.7033E-06  3053248.6565705878\n",
      "509  DataValue    7  25              4.30404E-06  2668054.0547751486\n",
      "510  DataValue    6  26              3.95369E-06  2928429.1905821725\n",
      "511  DataValue    5  27   3.6210800000000002E-06  2864344.6379468385\n",
      "512  DataValue    4  28   3.2554500000000003E-06  2887461.1997401281\n",
      "513  DataValue    3  29              2.92843E-06  3415942.2022579387\n",
      "514  DataValue    2  30   2.6699600000000004E-06  3026222.2154972837\n",
      "515  DataValue    1  31              2.26754E-06  519557.44097178022\n",
      "516  DataValue    0  32  -1.1794700000000001E-06  9654.6744989248054\n",
      "517  DataValue   -1  33  -0.00020488600000000002  4044.3296546852248\n",
      "518  DataValue   -2  34             -0.000495699  3210.8037123312524\n",
      "519  DataValue   -3  35             -0.000827783  2854.8548948628318\n",
      "520  DataValue   -4  36              -0.00119626  2605.6017832738603\n",
      "521  DataValue   -5  37              -0.00159536    2416.18846270009\n",
      "522  DataValue   -6  38              -0.00202401   2253.622698487819\n",
      "523  DataValue   -7  39              -0.00248282  2102.9609690444149\n",
      "524  DataValue   -8  40              -0.00297505  1967.6711627952736\n",
      "525  DataValue   -9  41              -0.00349925  1854.5650117764876\n",
      "526  DataValue  -10  42              -0.00405347  1804.3376276568879\n"
     ]
    }
   ],
   "source": [
    "index1 = liste_nom_mesures.iloc[1].name\n",
    "index2 = liste_nom_mesures.iloc[2].name\n",
    "\n",
    "#df_measure = df.loc[index1:index2][df[0].str.contains(\"DataValue\")]\n",
    "df_measure = df.loc[df[0].str.contains(\"DataValue\"), :].loc[index1:index2, :]\n",
    "\n",
    "\n",
    "print(df_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "ancien code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeff']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\michel.jeanneret\\Documents\\PROFESSIONNEL\\python\\Prober_station\\data_processing_prober_cmi.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Parcourir toutes les lignes du fichier CSV\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m reader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# Vérifier si la ligne satisfait le critère de filtrage\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m TestRecord.Remarks\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m row[(\u001b[39m1\u001b[39;49m)]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         \u001b[39m# Ajouter la ligne filtrée à la liste\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mqq\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/michel.jeanneret/Documents/PROFESSIONNEL/python/Prober_station/data_processing_prober_cmi.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         filtered_rows\u001b[39m.\u001b[39mappend(row)\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ouvrir le fichier CSV en mode lecture\n",
    "with open(fichier_csv.name, \"r\") as f:\n",
    "\n",
    "    # Créer un objet lecteur CSV\n",
    "    reader = csv.DictReader(f, delimiter=\",\")\n",
    "\n",
    "    # Récupérer les noms des colonnes\n",
    "    column_names = reader.fieldnames\n",
    "    print(column_names)\n",
    "\n",
    "    # Initialiser une liste pour stocker les lignes filtrées\n",
    "    filtered_rows = []\n",
    "\n",
    "    # Parcourir toutes les lignes du fichier CSV\n",
    "    for row in reader:\n",
    "\n",
    "        # Vérifier si la ligne satisfait le critère de filtrage\n",
    "        if \" TestRecord.Remarks\" in row:\n",
    "\n",
    "            # Ajouter la ligne filtrée à la liste\n",
    "            print(\"qq\")\n",
    "            filtered_rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Convertir la liste filtrée en DataFrame pandas\n",
    "import pandas as pd\n",
    "dataframe = pd.DataFrame(filtered_rows)\n",
    "print(dataframe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # Initialiser une liste pour stocker les lignes filtrées\n",
    "    filtered_rows = []\n",
    "\n",
    "    # Parcourir toutes les lignes du fichier CSV\n",
    "    for row in reader:\n",
    "\n",
    "        # Vérifier si la ligne satisfait le critère de filtrage\n",
    "        if \"TestRecord.Remarks\" in row:\n",
    "\n",
    "            # Ajouter la ligne filtrée à la liste\n",
    "            filtered_rows.append(row)\n",
    "\n",
    "# Convertir la liste filtrée en DataFrame pandas\n",
    "import pandas as pd\n",
    "dataframe = pd.DataFrame(filtered_rows)\n",
    "print(dataframe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            A                   B      C\n",
      "0          cx                 csd     dd\n",
      "1          qq  TestRecord.Remarks   nom1\n",
      "2          qq                  qq     qq\n",
      "3          pp                   p     dd\n",
      "4          qq                  ff      a\n",
      "5   DataValue                val1   val2\n",
      "6   DataValue                val3   val4\n",
      "7          qq                  ee     ff\n",
      "8          wd                  ww     ss\n",
      "9          qq  TestRecord.Remarks   nom2\n",
      "10         qq                  qq     qq\n",
      "11         pp                   p     dd\n",
      "12         qq                  fr      a\n",
      "13  DataValue                val5   val6\n",
      "14  DataValue                val7   val8\n",
      "15         ds                vfre     sd\n",
      "16         sg                ssfd     fs\n",
      "17         sd                 ffw   sfdf\n",
      "18         qq  TestRecord.Remarks   nom3\n",
      "19         qq                  qq     qq\n",
      "20        gds                  df     ew\n",
      "21         qq                  fr      a\n",
      "22  DataValue                val9  val10\n",
      "23  DataValue               val11  val12\n",
      "{'val1': 'val2', 'val3': 'val4'}\n",
      "{'val5': 'val6', 'val7': 'val8'}\n",
      "{'val9': 'val10', 'val11': 'val12'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Créer le tableau\n",
    "df = pd.DataFrame({'A': ['cx', 'qq', 'qq', 'pp', 'qq', 'DataValue', 'DataValue', 'qq', 'wd', 'qq', 'qq', 'pp', 'qq', 'DataValue', 'DataValue', 'ds', 'sg', 'sd', 'qq', 'qq', 'gds', 'qq', 'DataValue', 'DataValue'],\n",
    "                   'B': ['csd', 'TestRecord.Remarks', 'qq', 'p', 'ff', 'val1', 'val3', 'ee', 'ww', 'TestRecord.Remarks', 'qq', 'p', 'fr', 'val5', 'val7', 'vfre', 'ssfd', 'ffw', 'TestRecord.Remarks', 'qq', 'df', 'fr', 'val9', 'val11'],\n",
    "                   'C': ['dd', 'nom1', 'qq', 'dd', 'a', 'val2', 'val4', 'ff', 'ss', 'nom2', 'qq', 'dd', 'a', 'val6', 'val8', 'sd', 'fs', 'sfdf', 'nom3', 'qq', 'ew', 'a', 'val10', 'val12']})\n",
    "\n",
    "# Initialiser les variables\n",
    "dicts = {}\n",
    "current_dict = None\n",
    "\n",
    "# Parcourir chaque ligne du tableau\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    \n",
    "    # Si la cellule de la colonne B contient \"TestRecord.Remarks\"\n",
    "    if row['B'] == 'TestRecord.Remarks':\n",
    "        # Enregistrer le nom du dictionnaire en cours\n",
    "        current_dict = row['C']\n",
    "        # Initialiser le dictionnaire avec le nom de la cellule à droite\n",
    "        dicts[current_dict] = {}\n",
    "    # Si la cellule de la colonne A contient \"DataValue\"\n",
    "    elif row['A'] == 'DataValue':\n",
    "        # Ajouter les valeurs dans le dictionnaire en cours\n",
    "        dicts[current_dict][row['B']] = row['C']\n",
    "\n",
    "# Afficher les dictionnaires\n",
    "print(df)\n",
    "print(dicts['nom1'])\n",
    "print(dicts['nom2'])\n",
    "print(dicts['nom3'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE QUI MARCHE!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nom1', 'nom2', 'nom3']\n",
      "           0     1     2\n",
      "5  DataValue  val1  val2\n",
      "6  DataValue  val3  val4\n",
      "            0     1     2\n",
      "13  DataValue  val5  val6\n",
      "14  DataValue  val7  val8\n",
      "            0      1      2\n",
      "22  DataValue   val9  val10\n",
      "23  DataValue  val11  val12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Créer le tableau\n",
    "data = [['cx', 'csd', 'dd'],\n",
    "        ['qq', 'TestRecord.Remarks', 'nom1'],\n",
    "        ['qq', 'qq', 'qq'],\n",
    "        ['pp', 'p', 'dd'],\n",
    "        ['qq', 'ff', 'a'],\n",
    "        ['DataValue', 'val1', 'val2'],\n",
    "        ['DataValue', 'val3', 'val4'],\n",
    "        ['qq', 'ee', 'ff'],\n",
    "        ['wd', 'ww', 'ss'],\n",
    "        ['qq', 'TestRecord.Remarks', 'nom2'],\n",
    "        ['qq', 'qq', 'qq'],\n",
    "        ['pp', 'p', 'dd'],\n",
    "        ['qq', 'fr', 'a'],\n",
    "        ['DataValue', 'val5', 'val6'],\n",
    "        ['DataValue', 'val7', 'val8'],\n",
    "        ['ds', 'vfre', 'sd'],\n",
    "        ['sg', 'ssfd', 'fs'],\n",
    "        ['sd', 'ffw', 'sfdf'],\n",
    "        ['qq', 'TestRecord.Remarks', 'nom3'],\n",
    "        ['qq', 'qq', 'qq'],\n",
    "        ['gds', 'df', 'ew'],\n",
    "        ['qq', 'fr', 'a'],\n",
    "        ['DataValue', 'val9', 'val10'],\n",
    "        ['DataValue', 'val11', 'val12']]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "#print(df)\n",
    "\n",
    "# récupérer le nombre de colonnes dans df\n",
    "num_cols = df.shape[1]\n",
    "\n",
    "# Initialiser les variables\n",
    "dfs = {}\n",
    "current_df = None\n",
    "#current_index = 0\n",
    "\n",
    "# Parcourir chaque ligne du tableau\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    \n",
    "    # Si la cellule de la colonne B contient \"TestRecord.Remarks\"\n",
    "    if row[1] == 'TestRecord.Remarks':\n",
    "        # Enregistrer le nom du DataFrame en cours\n",
    "        current_df = row[2]\n",
    "        # créer un nouveau DataFrame avec les mêmes colonnes, mais sans données\n",
    "        dfs[current_df] = pd.DataFrame(columns=range(num_cols))\n",
    "        #current_index = 0\n",
    "    # Si la cellule de la colonne A contient \"DataValue\"\n",
    "    elif row[0] == 'DataValue':\n",
    "        # Ajouter les valeurs dans le DataFrame en cours\n",
    "        #dfs[current_df] = dfs[current_df].append(row)\n",
    "        dfs[current_df] = pd.concat([dfs[current_df], pd.DataFrame([row])])\n",
    "\n",
    "        #current_index += 1\n",
    "\n",
    "#print(df)\n",
    "\n",
    "print(list(dfs.keys()))\n",
    "\n",
    "# Afficher les DataFrames\n",
    "print(dfs['nom1'])\n",
    "print(dfs['nom2'])\n",
    "print(dfs['nom3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prober_station",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
